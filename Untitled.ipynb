{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                     #相关性热图\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 添加时间特征\n",
    "start_date = df['date'].min()\n",
    "df['DAY'] = (df['date'] - start_date).dt.days  # 整个数据集的第几天\n",
    "df['DOY'] = df['date'].dt.dayofyear  # 一年中的第几天\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15', 'DAY', 'DOY']\n",
    "target_variable = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对每个目标变量分别进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variable:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 计算相关性矩阵\n",
    "correlation_matrix = df_imputed[features + target_variable].corr()\n",
    "\n",
    "# 创建标准化后的数据框用于保存\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "for target in target_variable:\n",
    "    df_scaled[target] = df_imputed[target]\n",
    "\n",
    "# 将相关性矩阵和标准化后的数据保存到Excel文件的不同工作表\n",
    "output_file_path = r\"D:\\ML数据集\\相关性热图绘图数据\\相关性矩阵与标准化数据.xlsx\"\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    # 保存相关性矩阵到SHEET1\n",
    "    correlation_matrix.to_excel(writer, sheet_name=\"Correlation Matrix\")\n",
    "    \n",
    "    # 保存标准化后的数据到SHEET2\n",
    "    df_scaled.to_excel(writer, sheet_name=\"Scaled Data\", index=False)\n",
    "\n",
    "# 设置绘图尺寸\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 绘制热图\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Feature and Target Variable Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variable = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 处理缺失值和标准化\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = MinMaxScaler()\n",
    "X = df[features]\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# 计算特征之间的相关性矩阵\n",
    "corr_matrix = np.corrcoef(X_scaled, rowvar=False)\n",
    "\n",
    "# 基于特征之间的皮尔森相关系数进行层次聚类\n",
    "dist_matrix = pdist(1 - np.abs(corr_matrix))\n",
    "linkage_matrix = linkage(dist_matrix, method='average')\n",
    "\n",
    "# 设定一个阈值，将特征分成若干簇\n",
    "threshold = 0.5\n",
    "clusters = fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "\n",
    "# 打印每个特征所属的簇\n",
    "for feature, cluster in zip(features, clusters):\n",
    "    print(f'Feature: {feature}, Cluster: {cluster}')\n",
    "\n",
    "# 为每个簇选择一个代表特征\n",
    "selected_features = []\n",
    "for cluster_id in np.unique(clusters):\n",
    "    cluster_features = np.where(clusters == cluster_id)[0]\n",
    "    selected_feature = features[cluster_features[0]]\n",
    "    selected_features.append(selected_feature)\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "# 将所需的计算结果保存到字典中\n",
    "results = {\n",
    "    \"linkage_matrix\": linkage_matrix,\n",
    "    \"features\": features\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# 从结果字典中提取计算结果\n",
    "linkage_matrix = results[\"linkage_matrix\"]\n",
    "features = results[\"features\"]\n",
    "\n",
    "# 绘制层次聚类树状图\n",
    "plt.figure(figsize=(14, 8), linewidth=3)\n",
    "\n",
    "# 设置字体类型和大小\n",
    "plt.rcParams.update({'font.size': 16, 'font.family': 'Arial'})\n",
    "\n",
    "dendrogram(linkage_matrix, labels=features, leaf_rotation=90, leaf_font_size=15)\n",
    "plt.title('Hierarchical Clustering', fontsize=18, fontweight='bold', family='Arial')\n",
    "plt.xlabel('Features', fontsize=18, fontweight='bold', family='Arial')\n",
    "plt.ylabel('Distance', fontsize=18, fontweight='bold', family='Arial')\n",
    "\n",
    "# 设置x轴和y轴刻度字体\n",
    "plt.xticks(fontsize=15, fontfamily='Arial')\n",
    "plt.yticks(fontsize=15, fontfamily='Arial')\n",
    "\n",
    "# 删除背景方块并添加边框\n",
    "plt.gca().patch.set_facecolor('white')\n",
    "plt.gca().patch.set_edgecolor('black')\n",
    "for spine in plt.gca().spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(1.5)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.grid(False)\n",
    "\n",
    "# 保存为JPEG格式，dpi=300\n",
    "output_file_path = r\"D:\\ML数据集\\提交绘图源PPT\\层次聚类树状图.jpeg\"\n",
    "plt.savefig(output_file_path, format='jpeg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "\n",
    "# 排除日期时间列\n",
    "df = df.select_dtypes(exclude=['datetime'])\n",
    "\n",
    "# 处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df_imputed.columns)\n",
    "\n",
    "# 模型定义\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "def process_target(target):\n",
    "    local_importance_results = []\n",
    "    \n",
    "    X = df_scaled[features].values\n",
    "    y = df_scaled[target].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 计算排列重要性\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=42, n_jobs=-1)\n",
    "    importances = result.importances_mean\n",
    "    std = result.importances_std\n",
    "    \n",
    "    local_importance_results.append({\n",
    "        'Target': target,\n",
    "        'Features': features,\n",
    "        'Importances': importances,\n",
    "        'Std': std\n",
    "    })\n",
    "    \n",
    "    return local_importance_results\n",
    "\n",
    "# 初始化全局变量\n",
    "importance_results = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    futures = [executor.submit(process_target, target) for target in target_variables]\n",
    "    for future in futures:\n",
    "        local_importance_results = future.result()\n",
    "        importance_results.extend(local_importance_results)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "importance_df = pd.DataFrame(importance_results)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8149ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 确保已经计算出 importance_df\n",
    "\n",
    "# 转换数据格式以便绘制图\n",
    "data = {}\n",
    "targets = importance_df['Target'].unique()\n",
    "for target in targets:\n",
    "    data[target] = {}\n",
    "    for i, feature in enumerate(importance_df[importance_df['Target'] == target]['Features'].values[0]):\n",
    "        data[target][feature] = importance_df[importance_df['Target'] == target]['Importances'].values[0][i]\n",
    "\n",
    "# 为每个目标变量绘制单独的图\n",
    "for target in targets:\n",
    "    target_data = pd.DataFrame.from_dict(data[target], orient='index', columns=['Importance'])\n",
    "    target_data.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "    \n",
    "    # 绘制图形\n",
    "    plt.figure(figsize=(12, 6))  # 调整图形大小\n",
    "    \n",
    "    # 颜色映射\n",
    "    colors = sns.color_palette(\"Set3\", len(target_data))  # 使用Set3调色板\n",
    "    \n",
    "    # 绘制水平柱状图\n",
    "    target_data.plot(kind='barh', color=colors, edgecolor='k', legend=False)\n",
    "    \n",
    "    # 设置轴标签\n",
    "    plt.ylabel(\"Feature\", fontsize=15, labelpad=20)  # y轴标签大小和间距\n",
    "    plt.xlabel(\"Permutation Importance\", fontsize=15, labelpad=20)  # x轴标签大小和间距\n",
    "    \n",
    "    # 设置标题\n",
    "    plt.title(f\"Permutation Importance of Features for {target}\", fontsize=18, pad=20)  # 标题大小和间距\n",
    "    \n",
    "    # 设置刻度和标签\n",
    "    plt.xticks(fontsize=12)  # x轴刻度标签大小\n",
    "    plt.yticks(fontsize=12)  # y轴刻度标签大小\n",
    "    \n",
    "    # 添加网格\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.7)\n",
    "    \n",
    "    # 调整图表布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ccaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = DecisionTreeRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target):\n",
    "    results = []\n",
    "    predictions = []\n",
    "    cross_val_results = []\n",
    "\n",
    "    scaler_y = MinMaxScaler()\n",
    "    y_scaled = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 分割训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    # 使用RFE进行特征递归消除\n",
    "    rfe = RFE(estimator=best_model, n_features_to_select=1, step=1)\n",
    "    rfe.fit(X_train, y_train)\n",
    "    ranking = rfe.ranking_\n",
    "    sorted_features = np.array(features)[np.argsort(ranking)]\n",
    "\n",
    "    for n_features in range(len(features), 0, -1):\n",
    "        selected_features = sorted_features[:n_features]\n",
    "        print(f'Target: {target}, Remaining features ({n_features}): {list(selected_features)}')\n",
    "        \n",
    "        X_train_rfe = X_train[:, np.argsort(ranking)[:n_features]]\n",
    "        X_test_rfe = X_test[:, np.argsort(ranking)[:n_features]]\n",
    "        \n",
    "        # 进行五折交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_index = 1\n",
    "        for train_idx, test_idx in kfold.split(X_train_rfe):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            \n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))\n",
    "            fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "            fold_mae = mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "\n",
    "            cross_val_results.append({\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold_index,\n",
    "                'CV_RMSE': fold_rmse,\n",
    "                'CV_R²': fold_r2,\n",
    "                'CV_MAE': fold_mae\n",
    "            })\n",
    "            \n",
    "            fold_index += 1\n",
    "        \n",
    "        # 在测试集上进行预测并计算指标\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "        y_pred_test_unscaled = scaler_y.inverse_transform(y_pred_test.reshape(-1, 1)).ravel()\n",
    "        y_pred_train_unscaled = scaler_y.inverse_transform(y_pred_train.reshape(-1, 1)).ravel()\n",
    "        y_test_unscaled = scaler_y.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "        y_train_unscaled = scaler_y.inverse_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test_unscaled, y_pred_test_unscaled))\n",
    "        test_r2 = r2_score(y_test_unscaled, y_pred_test_unscaled)\n",
    "        test_mae = mean_absolute_error(y_test_unscaled, y_pred_test_unscaled)\n",
    "\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train_unscaled, y_pred_train_unscaled))\n",
    "        train_r2 = r2_score(y_train_unscaled, y_pred_train_unscaled)\n",
    "        train_mae = mean_absolute_error(y_train_unscaled, y_pred_train_unscaled)\n",
    "\n",
    "        # 记录模型性能\n",
    "        results.append({\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'Remaining Features': list(selected_features),\n",
    "            'Test_RMSE': test_rmse,\n",
    "            'Test_R²': test_r2,\n",
    "            'Test_MAE': test_mae,\n",
    "            'Train_RMSE': train_rmse,\n",
    "            'Train_R²': train_r2,\n",
    "            'Train_MAE': train_mae,\n",
    "            'Best_Params': best_params\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        predictions.append({\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test_unscaled.tolist(),\n",
    "            'y_pred_test': y_pred_test_unscaled.tolist(),\n",
    "            'y_train': y_train_unscaled.tolist(),\n",
    "            'y_pred_train': y_pred_train_unscaled.tolist()\n",
    "        })\n",
    "\n",
    "    return results, cross_val_results, predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "all_results = []\n",
    "all_cross_val_results = []\n",
    "all_predictions = []\n",
    "\n",
    "# 处理所有目标变量\n",
    "for target in target_variables:\n",
    "    target_results, target_cross_val_results, target_predictions = process_target(target)\n",
    "    all_results.extend(target_results)\n",
    "    all_cross_val_results.extend(target_cross_val_results)\n",
    "    all_predictions.extend(target_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(all_results)\n",
    "cross_val_results_df = pd.DataFrame(all_cross_val_results)\n",
    "predictions_df = pd.DataFrame(all_predictions)\n",
    "\n",
    "# 保存结果到Excel\n",
    "output_dir = r'D:\\ML数据集\\决策树递归消除和交叉验证结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, '递归消除_交叉验证结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Results', index=False)\n",
    "    cross_val_results_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c91555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = DecisionTreeRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'Decision Tree',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'Decision Tree',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'Decision Tree',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, '决策树模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00125b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # 森林中树的数量\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'Random Forest',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'Random Forest',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'Random Forest',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, '随机森林模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # 弱学习器的数量\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # 学习率\n",
    "    'max_depth': [3, 5, 7],  # 每个树的最大深度\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = GradientBoostingRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'Gradient Boosting',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'Gradient Boosting',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'Gradient Boosting',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'GBDT模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ffb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # 弱学习器的数量\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # 学习率\n",
    "    'max_depth': [3, 5, 7],  # 每个树的最大深度\n",
    "    'min_child_weight': [1, 3, 5],  # 控制子叶节点中最小的样本权重和\n",
    "    'subsample': [0.6, 0.8, 1.0],  # 每棵树对样本的采样比例\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]  # 每棵树对特征的采样比例\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'XGBoost',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'XGBoost',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'XGBoost',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'XGBoost模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfdebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100,), (100, 50)],  # 隐藏层的结构\n",
    "    'activation': ['relu', 'tanh'],  # 激活函数\n",
    "    'solver': ['adam', 'lbfgs'],  # 优化器\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # 正则化参数\n",
    "    'learning_rate': ['constant', 'adaptive']  # 学习率\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = MLPRegressor(max_iter=1000, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'ANN',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'ANN',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'ANN',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'ANN模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e697ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 定义超参数搜索空间\n",
    "param_grid = {\n",
    "    'n_neighbors': [1, 2],  # 邻居的数量\n",
    "    'weights': ['uniform'],  # 权重函数\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # 近邻算法\n",
    "    'p': [1, 2]  # 距离度量，1代表曼哈顿距离，2代表欧几里得距离\n",
    "}\n",
    "\n",
    "# 模型定义\n",
    "base_model = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(estimator=base_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1)\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 进行超参数搜索\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # 打印最优参数\n",
    "    print(f\"Best Parameters for target {target}: {best_params}\")\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'KNN',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'KNN',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'KNN',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'KNN模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['WS2', 'WS10', 'AT2', 'RH2', 'VP2', 'AT10', 'RH10', 'VP10', 'AP', 'PR', 'PRR', 'DR', 'UR', 'DLR', 'ULR', 'Rn', 'ALB', 'TNR', 'SG5', 'SG15']\n",
    "target_variables = ['ST5', 'SVWC5']\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 对所有特征进行归一化处理\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(df_imputed[features])\n",
    "\n",
    "# 对所有目标变量进行归一化处理\n",
    "scaler_y = MinMaxScaler()\n",
    "for target in target_variables:\n",
    "    df_imputed[target] = scaler_y.fit_transform(df_imputed[target].values.reshape(-1, 1))\n",
    "\n",
    "# 模型定义\n",
    "base_model = LinearRegression()\n",
    "# 注意：线性回归模型没有超参数需要调整，所以我们不需要使用 GridSearchCV\n",
    "# 直接用 KFold 进行交叉验证\n",
    "\n",
    "def process_target(target, selected_features):\n",
    "    local_results = []\n",
    "    local_cross_val_results = []\n",
    "    local_predictions = []\n",
    "\n",
    "    # 提取归一化后的目标变量\n",
    "    y_scaled = df_imputed[target].values\n",
    "    y = y_scaled.ravel()\n",
    "    \n",
    "    # 提取对应的归一化后的特征\n",
    "    X_selected = df_imputed[selected_features].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 不进行反归一化处理，直接使用归一化后的数据进行计算\n",
    "\n",
    "    # 训练模型\n",
    "    best_model = base_model\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    for n_features in range(len(selected_features), 0, -1):\n",
    "        X_train_rfe = X_train[:, :n_features]\n",
    "        X_test_rfe = X_test[:, :n_features]\n",
    "        best_model.fit(X_train_rfe, y_train)\n",
    "        y_pred_test = best_model.predict(X_test_rfe)\n",
    "        y_pred_train = best_model.predict(X_train_rfe)\n",
    "\n",
    "        # 记录模型性能\n",
    "        local_results.append({\n",
    "            'Model': 'Linear Regression',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train),\n",
    "        })\n",
    "\n",
    "        # 保存预测值和真实值\n",
    "        local_predictions.append({\n",
    "            'Model': 'Linear Regression',\n",
    "            'Target': target,\n",
    "            'n_features': n_features,\n",
    "            'y_test': y_test.tolist(),\n",
    "            'y_pred_test': y_pred_test.tolist(),\n",
    "            'y_train': y_train.tolist(),\n",
    "            'y_pred_train': y_pred_train.tolist(),\n",
    "            'RMSE_test': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'R²_test': r2_score(y_test, y_pred_test),\n",
    "            'MAE_test': mean_absolute_error(y_test, y_pred_test),\n",
    "            'RMSE_train': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'R²_train': r2_score(y_train, y_pred_train),\n",
    "            'MAE_train': mean_absolute_error(y_train, y_pred_train)\n",
    "        })\n",
    "\n",
    "        # 交叉验证\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for fold, (train_idx, test_idx) in enumerate(kfold.split(X_train_rfe)):\n",
    "            X_train_fold, X_test_fold = X_train_rfe[train_idx], X_train_rfe[test_idx]\n",
    "            y_train_fold, y_test_fold = y_train[train_idx], y_train[test_idx]\n",
    "            best_model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = best_model.predict(X_test_fold)\n",
    "            local_cross_val_results.append({\n",
    "                'Model': 'Linear Regression',\n",
    "                'Target': target,\n",
    "                'n_features': n_features,\n",
    "                'Fold': fold + 1,\n",
    "                'CV_RMSE': np.sqrt(mean_squared_error(y_test_fold, y_pred_fold)),\n",
    "                'CV_R²': r2_score(y_test_fold, y_pred_fold),\n",
    "                'CV_MAE': mean_absolute_error(y_test_fold, y_pred_fold)\n",
    "            })\n",
    "\n",
    "    return local_results, local_cross_val_results, local_predictions\n",
    "\n",
    "# 初始化全局变量\n",
    "results = []\n",
    "cross_val_results = []\n",
    "predictions = []\n",
    "\n",
    "# 指定核心数\n",
    "num_cores = 1\n",
    "\n",
    "# 使用多线程并行处理\n",
    "with ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
    "    target_feature_pairs = [\n",
    "        ('ST5', ['RH10',  'SG15', 'AT10','PRR']),  \n",
    "        ('SVWC5', ['RH10', 'PRR',  'SG15', 'VP2']), \n",
    "    ]\n",
    "    futures = [executor.submit(process_target, target, features) for target, features in target_feature_pairs]\n",
    "    for future in futures:\n",
    "        local_results, local_cross_val_results, local_predictions = future.result()\n",
    "        results.extend(local_results)\n",
    "        cross_val_results.extend(local_cross_val_results)\n",
    "        predictions.extend(local_predictions)\n",
    "\n",
    "# 将结果转换为数据框\n",
    "results_df = pd.DataFrame(results)\n",
    "cross_val_df = pd.DataFrame(cross_val_results)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# 保存计算结果为Excel文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, '线性回归模型计算结果.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    results_df.to_excel(writer, sheet_name='Model_Performance', index=False)\n",
    "    cross_val_df.to_excel(writer, sheet_name='Cross_Validation_Results', index=False)\n",
    "    predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"模型计算完成\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(f\"结果已保存到: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from alibi.explainers import ALE\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "target_features_map = {\n",
    "    'ST5': ['AT10', 'RH10', 'SG15', 'PRR', 'SVWC5'],\n",
    "    'SVWC5': ['PRR', 'SG15', 'VP2', 'RH10', 'ST5']\n",
    "}\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# 填补缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 初始化 ALE 结果保存字典\n",
    "ale_plot_data = {}\n",
    "\n",
    "# 遍历每个目标变量，训练模型并保存ALE\n",
    "for target, features in target_features_map.items():\n",
    "    # 分割数据集，不进行归一化\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_imputed[features], df_imputed[target], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 将 X_train 转换为 numpy 数组\n",
    "    X_train_np = X_train.values\n",
    "    \n",
    "    # 训练随机森林模型\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
    "    model.fit(X_train_np, y_train)\n",
    "    \n",
    "    # 计算 ALE\n",
    "    ale_explainer = ALE(model.predict, feature_names=features)\n",
    "    ale_result = ale_explainer.explain(X_train_np)\n",
    "    \n",
    "    # 保存绘图数据\n",
    "    for i, feature in enumerate(features):\n",
    "        feature_values = np.ravel(ale_result.feature_values[i])\n",
    "        ale_values = np.ravel(ale_result.ale_values[i])\n",
    "        plot_data = pd.DataFrame({\n",
    "            f'{feature}_values': feature_values,\n",
    "            f'{feature}_ale': ale_values\n",
    "        })\n",
    "        ale_plot_data[f'{target}_{feature}'] = plot_data\n",
    "    \n",
    "        # 绘制ALE图\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(feature_values, ale_values)\n",
    "        plt.title(f'ALE Plot for {target} - {feature}')\n",
    "        plt.xlabel(f'{feature}')\n",
    "        plt.ylabel('ALE')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# 保存 ALE 绘图数据为 xlsx 文件\n",
    "output_dir = r'D:\\ML数据集\\聚类分析计算结果\\ALE计算结果'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_xlsx_path = os.path.join(output_dir, 'ale_plot_data.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(output_xlsx_path) as writer:\n",
    "    for sheet_name, data in ale_plot_data.items():\n",
    "        data.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"ALE绘图数据已保存为Excel文件：{output_xlsx_path}\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n",
    "print(df_imputed['RH10'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取数据集\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_事件数据\\CPE_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "features = ['VP2', 'RH10', 'APR', 'HF15']\n",
    "target_variable = 'SVWC5'\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features], \n",
    "    df[target_variable], \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 训练随机森林模型\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from matplotlib import font_manager\n",
    "\n",
    "# 设置自定义字体（可选）\n",
    "# 请确保系统中安装了对应的字体\n",
    "# font_path = 'C:/Windows/Fonts/Arial.ttf'  # 修改为你想要的字体路径\n",
    "# font_prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "# 全局设置字体大小和字体族\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = 'Arial'  # 可根据需要修改\n",
    "\n",
    "# 定义轴标签和标题的字体大小\n",
    "label_fontsize = 16\n",
    "title_fontsize = 16\n",
    "tick_fontsize = 16\n",
    "\n",
    "# 绘制特征的PDP和ICE图\n",
    "for i, feature in enumerate(features):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6),dpi=300)\n",
    "    \n",
    "    # 绘制PDP和ICE\n",
    "    display = PartialDependenceDisplay.from_estimator(\n",
    "        model, \n",
    "        X_train, \n",
    "        features=[feature], \n",
    "        kind=\"both\", \n",
    "        ice_lines_kw={'color': 'lightblue', 'alpha': 0.3},  # ICE线样式\n",
    "        pd_line_kw={'color': '#4682B4', 'linewidth': 2},        # PDP线样式\n",
    "        ax=ax,\n",
    "        line_kw={'label': 'PDP'},  # 添加PDP图例标签\n",
    "    )\n",
    "    \n",
    "    # 设置标题和轴标签\n",
    "    ax.set_title(f'Partial Dependence and ICE for {feature}', fontsize=title_fontsize)\n",
    "    ax.set_xlabel(f'{feature}', fontsize=label_fontsize)\n",
    "    ax.set_ylabel('Partial Dependence', fontsize=label_fontsize)\n",
    "    \n",
    "    # 设置刻度字体大小\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "    \n",
    "    # 添加图例\n",
    "    ax.legend(fontsize=label_fontsize)\n",
    "    \n",
    "    # 优化布局\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"C:\\Users\\SS\\Desktop\\论文\\Machine learning\\Machine learning 数据集\\无道砟训练集\\有道砟训练集.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 查看数据列名\n",
    "print(df.columns)\n",
    "\n",
    "# 确保 'date' 列存在并解析日期\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "else:\n",
    "    raise KeyError(\"'date' 列不存在于数据集中\")\n",
    "\n",
    "# 数据预处理\n",
    "features = ['PRR', 'AT10', 'RH10', 'SG15']\n",
    "target_variables = ['ST5']\n",
    "\n",
    "# 处理缺失值\n",
    "df = df.select_dtypes(exclude=['datetime64'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 模型定义\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=20)\n",
    "\n",
    "def process_target(target):\n",
    "    X = df_imputed[features].values\n",
    "    y = df_imputed[target].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model, X_test\n",
    "\n",
    "# 初始化全局变量\n",
    "trained_models = {}\n",
    "X_tests = {}\n",
    "\n",
    "# 处理每个目标变量\n",
    "for target in target_variables:\n",
    "    model, X_test = process_target(target)\n",
    "    trained_models[target] = model\n",
    "    X_tests[target] = X_test\n",
    "\n",
    "# 创建一个函数绘制PDP图并保存数据\n",
    "def plot_single_pdp(model, df, feature, target, writer):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    pdp_display = PartialDependenceDisplay.from_estimator(model, df, [feature], feature_names=features, grid_resolution=1000, ax=ax)\n",
    "    pdp_values = pdp_display.lines_[0][0].get_ydata()\n",
    "    pdp_grid = pdp_display.lines_[0][0].get_xdata()\n",
    "\n",
    "    pdp_df = pd.DataFrame({\n",
    "        'Quantiles': pdp_grid,\n",
    "        'PDP': pdp_values\n",
    "    })\n",
    "    \n",
    "    # 绘制PDP图\n",
    "    plt.cla()  # 清除之前的图形\n",
    "    sns.lineplot(x='Quantiles', y='PDP', data=pdp_df)\n",
    "    plt.title(f'PDP for {feature} (Target: {target})')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('PDP')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # 保存PDP数据到Excel\n",
    "    sheet_name = f'{target}_{feature}_PDP'\n",
    "    pdp_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# 保存PDP数据的文件路径\n",
    "output_file = r\"D:\\ML数据集\\聚类分析计算PKL  ALE PDP结果\\PDP计算结果\\PDP_STresults.xlsx\"\n",
    "\n",
    "# 使用ExcelWriter保存多个工作表\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    for target in target_variables:\n",
    "        model = trained_models[target]\n",
    "        X_test = X_tests[target]\n",
    "        for feature in features:\n",
    "            plot_single_pdp(model, df_imputed[features], feature, target, writer)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(\"PDP计算完成并保存至Excel文件\")\n",
    "print(f\"总运行时间: {total_time:.2f}秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e800d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 防止 shap 检查 transformers\n",
    "shap.utils.transformers.is_transformers_model = lambda x: False\n",
    "shap.utils.transformers.is_transformers_lm = lambda x: False\n",
    "shap.utils.transformers.safe_isinstance = lambda obj, class_path_str: False\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_事件数据\\春季.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['VP2', 'RH10', 'PRR', 'SG15']\n",
    "target_variable = 'SVWC5'\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 使用未归一化的特征值划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_imputed[features], df_imputed[target_variable], test_size=0.3, random_state=42)\n",
    "\n",
    "# 使用随机森林回归模型\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 计算 SHAP 值\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# 选择两个感兴趣的特征\n",
    "feature_1 = 'VP2'\n",
    "feature_2 = 'RH10'\n",
    "feature_1_index = features.index(feature_1)\n",
    "feature_2_index = features.index(feature_2)\n",
    "\n",
    "# 生成网格数据\n",
    "feature_1_values = np.linspace(X_train[feature_1].min(), X_train[feature_1].max(), 50)\n",
    "feature_2_values = np.linspace(X_train[feature_2].min(), X_train[feature_2].max(), 50)\n",
    "grid_x, grid_y = np.meshgrid(feature_1_values, feature_2_values)\n",
    "\n",
    "# 计算网格点的 SHAP 值\n",
    "shap_interaction_grid = np.zeros_like(grid_x)\n",
    "\n",
    "for i in range(grid_x.shape[0]):\n",
    "    for j in range(grid_x.shape[1]):\n",
    "        temp = X_train.copy()\n",
    "        temp[feature_1] = grid_x[i, j]\n",
    "        temp[feature_2] = grid_y[i, j]\n",
    "        shap_interaction_grid[i, j] = explainer.shap_values(temp).mean(axis=0)[feature_1_index] + explainer.shap_values(temp).mean(axis=0)[feature_2_index]\n",
    "\n",
    "# 绘制等高线图\n",
    "plt.contourf(grid_x, grid_y, shap_interaction_grid, cmap='viridis')\n",
    "plt.colorbar(label=\"SHAP Value\")\n",
    "plt.xlabel(feature_1)\n",
    "plt.ylabel(feature_2)\n",
    "plt.title(f\"SHAP Interaction for {feature_1} and {feature_2}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_事件数据\\春季.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = ['VP2', 'RH10', 'PRR', 'SG15']\n",
    "target_variable = 'SVWC5'\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 使用未归一化的特征值划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_imputed[features], df_imputed[target_variable], test_size=0.3, random_state=42)\n",
    "\n",
    "# 使用随机森林回归模型\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 计算部分依赖数据\n",
    "pdp_result = partial_dependence(\n",
    "    model, X_train, features=[(0, 1)], grid_resolution=50\n",
    ")\n",
    "\n",
    "# 提取网格数据和平均依赖数据\n",
    "XX, YY = np.meshgrid(pdp_result['grid_values'][0], pdp_result['grid_values'][1])\n",
    "Z = pdp_result['average'][0].T  # 将average进行转置以匹配网格形状\n",
    "\n",
    "# 将数据整理成 DataFrame\n",
    "df_grid = pd.DataFrame(Z, index=YY[:, 0], columns=XX[0, :])\n",
    "\n",
    "# 绘制图像以确保生成的部分依赖图正确\n",
    "plt.contourf(XX, YY, Z, cmap='viridis')\n",
    "plt.colorbar(label=\"Partial Dependence\")\n",
    "plt.xlabel('PRR')\n",
    "plt.ylabel('VP2')\n",
    "plt.title('2D Partial Dependence Plot for VP2 and RH10')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# 读取数据集\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_事件数据\\CPE_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "features = ['AT10', 'RH10', 'APR', 'HF15']\n",
    "target_variable = 'ST5'\n",
    "\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[features],\n",
    "    df[target_variable],\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 训练随机森林模型\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 全局设置字体大小和字体族\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['font.family'] = 'Arial'  # 可根据需要修改\n",
    "\n",
    "# 定义轴标签和标题的字体大小\n",
    "label_fontsize = 16\n",
    "title_fontsize = 16\n",
    "tick_fontsize = 16\n",
    "\n",
    "# 为每个特征单独绘制导数图\n",
    "for feature_idx, feature in enumerate(features):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6),dpi=300)\n",
    "    \n",
    "    # 为当前特征生成值的范围\n",
    "    feature_values = np.linspace(X_train[feature].min(), X_train[feature].max(), 100)\n",
    "    \n",
    "    # 初始化导数存储列表\n",
    "    derivatives = []\n",
    "    \n",
    "    # 对于每个样本，计算其在不同特征值下的预测值，并计算偏导数\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_temp = X_train.copy()\n",
    "        ice_values = []\n",
    "        \n",
    "        for val in feature_values:\n",
    "            X_temp[feature] = val\n",
    "            pred = model.predict(X_temp)\n",
    "            ice_values.append(pred)\n",
    "        \n",
    "        ice_values = np.array(ice_values)\n",
    "        smoothed_ice = gaussian_filter1d(ice_values, sigma=2, axis=0)\n",
    "        \n",
    "        # 确保 smoothed_ice 的维度匹配 feature_values\n",
    "        smoothed_ice = smoothed_ice[:, i]  # 选择第 i 个样本的 ICE 线\n",
    "        \n",
    "        # 计算平滑后ICE曲线的导数\n",
    "        derivative = np.gradient(smoothed_ice, feature_values)  # 不指定 axis，因为是一维数据\n",
    "        derivatives.append(derivative)\n",
    "    \n",
    "    derivatives = np.array(derivatives).T  # 转置以使其形状正确\n",
    "\n",
    "    mean_derivative = np.mean(derivatives, axis=1)  # 计算沿样本的平均值\n",
    "    std_derivative = np.std(derivatives, axis=1)\n",
    "    \n",
    "    # 绘制导数ICE曲线\n",
    "    ax.plot(feature_values, mean_derivative, color='black', linewidth=2, label='Mean Derivative ICE')\n",
    "    ax.fill_between(feature_values, mean_derivative - std_derivative, \n",
    "                    mean_derivative + std_derivative, color='gray', alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel(feature, fontsize=label_fontsize)\n",
    "    ax.set_ylabel('Partial Derivative', fontsize=label_fontsize)\n",
    "    ax.set_title(f'Derivative ICE for {feature}', fontsize=title_fontsize)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "    ax.legend(fontsize=label_fontsize)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.impute import SimpleImputer\n",
    "from itertools import combinations\n",
    "\n",
    "# 读取数据\n",
    "file_path = r\"D:\\ML数据集\\CPE\\CPE_事件数据\\春季.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 确保 'date' 列是 datetime 类型\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 数据预处理\n",
    "features = [ 'PRR','AT10', 'SG15', 'RH10']\n",
    "target_variable = 'ST5'\n",
    "\n",
    "# 删除日期列\n",
    "df = df.drop(columns=['date'])\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# 使用未归一化的特征值划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_imputed[features], df_imputed[target_variable], test_size=0.3, random_state=42)\n",
    "\n",
    "# 使用随机森林回归模型\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 创建一个ExcelWriter对象，用于保存不同的sheet\n",
    "output_file = r\"D:\\ML数据集\\CPE\\二阶PDP\\ST5春季all_contour_data.xlsx\"\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    # 遍历所有特征组合的二阶PDP\n",
    "    for feature_pair in combinations(range(len(features)), 2):\n",
    "        # 计算部分依赖数据\n",
    "        pdp_result = partial_dependence(\n",
    "            model, X_train, features=[feature_pair], grid_resolution=50\n",
    "        )\n",
    "\n",
    "        # 提取网格数据和平均依赖数据\n",
    "        XX, YY = np.meshgrid(pdp_result['grid_values'][0], pdp_result['grid_values'][1])\n",
    "        Z = pdp_result['average'][0].T  # 将average进行转置以匹配网格形状\n",
    "\n",
    "        # 将数据整理成 DataFrame，并添加特征组合名称\n",
    "        feature_names = [features[feature_pair[0]], features[feature_pair[1]]]\n",
    "        df_grid = pd.DataFrame(Z, index=YY[:, 0], columns=XX[0, :])\n",
    "        \n",
    "        # 将当前结果保存到Excel文件中的不同sheet\n",
    "        sheet_name = f\"{feature_names[0]}_vs_{feature_names[1]}\"\n",
    "        df_grid.to_excel(writer, sheet_name=sheet_name)\n",
    "        \n",
    "        # 绘制每个特征组合的二阶PDP图\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.contourf(XX, YY, Z, cmap='viridis')\n",
    "        plt.colorbar(label=\"Partial Dependence\")\n",
    "        plt.xlabel(feature_names[0])\n",
    "        plt.ylabel(feature_names[1])\n",
    "        plt.title(f'2D Partial Dependence Plot for {feature_names[0]} and {feature_names[1]}')\n",
    "        plt.show()\n",
    "\n",
    "print(f\"所有绘图数据已保存为 {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
